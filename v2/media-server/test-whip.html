<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WHIP Test Client</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: bold;
        }
        .status.connected {
            background-color: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        .status.disconnected {
            background-color: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        .status.connecting {
            background-color: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }
        button {
            background-color: #007bff;
            color: white;
            border: none;
            padding: 12px 24px;
            margin: 5px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 16px;
        }
        button:hover {
            background-color: #0056b3;
        }
        button:disabled {
            background-color: #6c757d;
            cursor: not-allowed;
        }
        .audio-meter {
            width: 100%;
            height: 50px;
            background-color: #e9ecef;
            border-radius: 5px;
            margin: 10px 0;
            position: relative;
            overflow: hidden;
        }
        .audio-level {
            height: 100%;
            background: linear-gradient(90deg, #28a745, #ffc107, #dc3545);
            width: 0%;
            transition: width 0.1s ease;
        }
        .logs {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 15px;
            margin-top: 20px;
            max-height: 300px;
            overflow-y: auto;
            font-family: monospace;
            font-size: 12px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>WHIP Test Client</h1>
        <p>Test the WebRTC WHIP endpoint for audio echo functionality.</p>
        
        <div id="status" class="status disconnected">
            Status: Disconnected
        </div>
        
        <div>
            <button id="startBtn" onclick="startStreaming()">Start Streaming</button>
            <button id="stopBtn" onclick="stopStreaming()" disabled>Stop Streaming</button>
        </div>
        
        <div class="audio-meter">
            <div id="audioLevel" class="audio-level"></div>
        </div>
        
        <div class="logs" id="logs"></div>
    </div>

    <script>
        let peerConnection = null;
        let localStream = null;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let animationId = null;

        function log(message) {
            const logs = document.getElementById('logs');
            const timestamp = new Date().toLocaleTimeString();
            logs.innerHTML += `[${timestamp}] ${message}\n`;
            logs.scrollTop = logs.scrollHeight;
        }

        function updateStatus(status, className) {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = `Status: ${status}`;
            statusDiv.className = `status ${className}`;
        }

        async function startStreaming() {
            try {
                log('Starting streaming...');
                updateStatus('Connecting', 'connecting');
                
                // Get microphone access
                localStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 48000
                    }
                });
                
                log('Microphone access granted');
                
                // Create WebRTC peer connection
                peerConnection = new RTCPeerConnection({
                    iceServers: [
                        { urls: 'stun:stun.l.google.com:19302' },
                        { urls: 'stun:stun1.l.google.com:19302' }
                    ]
                });
                
                // Add local audio track
                localStream.getTracks().forEach(track => {
                    peerConnection.addTrack(track, localStream);
                });
                
                // Handle incoming audio
                peerConnection.ontrack = (event) => {
                    log('Received remote audio track');
                    setupAudioVisualization(event.streams[0]);
                };
                
                // Handle connection state changes
                peerConnection.onconnectionstatechange = () => {
                    log(`Connection state: ${peerConnection.connectionState}`);
                    if (peerConnection.connectionState === 'connected') {
                        updateStatus('Connected', 'connected');
                        document.getElementById('startBtn').disabled = true;
                        document.getElementById('stopBtn').disabled = false;
                    } else if (peerConnection.connectionState === 'disconnected') {
                        updateStatus('Disconnected', 'disconnected');
                        document.getElementById('startBtn').disabled = false;
                        document.getElementById('stopBtn').disabled = true;
                    }
                };
                
                // Create offer
                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);
                
                log('Sending WHIP request...');
                
                // Send WHIP request
                const response = await fetch('http://localhost:8080/whip', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/sdp'
                    },
                    body: offer.sdp
                });
                
                if (!response.ok) {
                    throw new Error(`WHIP request failed: ${response.status}`);
                }
                
                const answerSdp = await response.text();
                log('Received WHIP response');
                
                // Set remote description
                await peerConnection.setRemoteDescription({
                    type: 'answer',
                    sdp: answerSdp
                });
                
                log('WebRTC connection established');
                
            } catch (error) {
                log(`Error: ${error.message}`);
                updateStatus('Error', 'disconnected');
                stopStreaming();
            }
        }

        function stopStreaming() {
            log('Stopping streaming...');
            
            if (animationId) {
                cancelAnimationFrame(animationId);
                animationId = null;
            }
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            if (localStream) {
                localStream.getTracks().forEach(track => track.stop());
                localStream = null;
            }
            
            if (peerConnection) {
                peerConnection.close();
                peerConnection = null;
            }
            
            updateStatus('Disconnected', 'disconnected');
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            
            // Reset audio meter
            document.getElementById('audioLevel').style.width = '0%';
            
            log('Streaming stopped');
        }

        function setupAudioVisualization(stream) {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                function updateAudioMeter() {
                    analyser.getByteFrequencyData(dataArray);
                    
                    // Calculate average volume
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const average = sum / bufferLength;
                    
                    // Update visual meter
                    const audioLevel = document.getElementById('audioLevel');
                    audioLevel.style.width = `${average}%`;
                    
                    animationId = requestAnimationFrame(updateAudioMeter);
                }
                
                updateAudioMeter();
                log('Audio visualization started');
                
            } catch (error) {
                log(`Audio visualization error: ${error.message}`);
            }
        }

        // Initialize
        log('WHIP Test Client loaded');
        log('Click "Start Streaming" to begin audio echo test');
    </script>
</body>
</html> 